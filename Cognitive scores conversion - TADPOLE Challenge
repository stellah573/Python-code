PYTHON CODE

"""
MADE BY: STELLAH LEE
PROJECT: Cognitive scores conversion from TADPOLE Challenge
---------------------------------------------------------
Introduction:
There are a lot of different cognitive tests to check if a patient have Alzheimerâ€™s Disease or any cognitive impairment.
A few example of the tests: CDRSB, ADAS11, ADAS13, MMSE
The idea is to reduce tests to do for same patient.
If a patient did three of the tests, we can convert three scores to the remaining one.
This notebook will contain data exploration, preparation, modelling, evaluation and a sample prediction example at the end.
For evaluation, we use the coefficient of determination of the prediction (R^2).
R^2 is closer to 1 means a better fit. MMSE will also be generated.
In this score conversion, I will give three demonstrations.
First and second one are linear model of two variables.
Third one is a general model that we can use other three scores to predict MMSE (TARGET).
Same procedures with different X, Y input can do the prediction of other scores(TARGET).
"""

import pandas as pd
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
import numpy as np

#load data
load_data = pd.read_csv('TADPOLE_D1_D2.csv')

#step1: just take the coloumns we need and check info
data_1 = load_data.iloc[:, 21:25];
data_1.info();

#step2: drop null values
#we still have 8702 non-null values which is still large to do the conversion
data_2 = data_1.dropna(axis=0, how='any');
print(data_2.info());
print(data_2.head());
print(data_2.describe())
data_2.plot(subplots = True, kind='box');

#check correlation betweek each score
scatter_matrix(data_2, alpha = 0.5, figsize = (6, 6), diagonal='kde');
print(data_2.corr())

#Setup one to one linear model
MMSE = data_2['MMSE'].values.reshape(-1, 1)
CDRSB = data_2['CDRSB'].values.reshape(-1, 1)
ADAS11 = data_2['ADAS11'].values.reshape(-1, 1)
ADAS13 = data_2['ADAS13'].values.reshape(-1, 1)

####################
#first example: MMSE to CDRSB
linreg1 = LinearRegression()

X1_train, X1_test, Y1_train, Y1_test = train_test_split(MMSE, CDRSB, test_size = 0.3, random_state=10)

linreg1.fit(X1_train, Y1_train)

# Predict on the test data: y_pred
Y1_pred = linreg1.predict(X1_test)

# Compute and print R^2 and RMSE
print("R^2: {}".format(linreg1.score(X1_test, Y1_test)))
rmse1 = np.sqrt(mean_squared_error(Y1_test, Y1_pred))
print("Root Mean Squared Error: {}".format(rmse1))

#Coefficient& Intercept
coef1 = linreg1.fit(X1_train, Y1_train).coef_
intercept1 = linreg1.fit(X1_train, Y1_train).intercept_
print('The equation is: ')
print('[CDRSB] = %0.2f [MMSE] + %0.2f' %(coef1, intercept1) )

#Plotting
plt.plot(X1_test, Y1_pred, color='Blue')
plt.scatter(X1_test, Y1_test, color='Red', marker='o')
plt.title('MMSE VS CDRSB')
plt.xlabel('MMSE')
plt.ylabel('CDRSB')
plt.show()

"""From the results, we can tell there is a negative correlation but the performance is not ideal."""

#############
#Second example: ADAS11 to ADAS13
linreg2 = LinearRegression()

X2_train, X2_test, Y2_train, Y2_test = train_test_split(ADAS11, ADAS13, test_size = 0.3, random_state=10)

linreg2.fit(X2_train, Y2_train)

# Predict on the test data: y_pred
Y2_pred = linreg2.predict(X2_test)

# Compute and print R^2 and RMSE
print("R^2: {}".format(linreg2.score(X2_test, Y2_test)))
rmse2 = np.sqrt(mean_squared_error(Y2_test, Y2_pred))
print("Root Mean Squared Error: {}".format(rmse2))

#Coefficient
coef2 = linreg2.fit(X2_train, Y2_train).coef_
intercept2 = linreg2.fit(X2_train, Y2_train).intercept_
print('The equation is: ')
print('[ADAS13] = %0.2f [ADAS11] + %0.2f' %(coef2, intercept2) )

#Plotting
plt.plot(X2_test, Y2_pred, color='Blue')
plt.scatter(X2_test, Y2_test, color='Red', marker='o')
plt.title('ADAS11 VS ADAS13')
plt.xlabel('ADAS11')
plt.ylabel('ADAS13')
plt.show()

"""From the results, we can use one to predict another one with a good performance."""

#Setup Multiple Linear Regression (MLR), target as MMSE
X = data_2.drop('MMSE', axis=1).values
Y = data_2['MMSE'].values

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=10)

MLRReg = LinearRegression()

MLRReg.fit(X_train, Y_train)

# Predict on the test data: y_pred
Y_pred = MLRReg.predict(X_test)

# Compute and print R^2 and RMSE
print("R^2: {}".format(MLRReg.score(X_test, Y_test)))
rmseMLR = np.sqrt(mean_squared_error(Y_test, Y_pred))
print("Root Mean Squared Error: {}".format(rmseMLR))

MLR_coef = MLRReg.fit(X_train,Y_train).coef_
MLR_intercept = MLRReg.fit(X_train,Y_train).intercept_
print('The equation is:')
print('[MMSE] = %0.2f [CDRSB] + (%0.2f)[ADAS11] + (%0.2f)[ADAS13] + (%0.2f)' 
      %(MLR_coef[0],MLR_coef[1], MLR_coef[2], MLR_intercept))

"""This model can convert CDRSB, ADAS11 and ADAS13 to MMSE.
We can swap the X, Y to do conversion to another score, e.g. predict CDRSB using three other scores."""

#Apply the model and predict one of the data (1001th)
example = data_2.loc[1000].values[0:3].reshape(1, -1)
real_value = data_2.loc[1000].values[3]
pred_value = MLRReg.predict(example)
print('Predicted value for the 1001th data: %0.2f and real value is %0.2f' %(pred_value, real_value))

###########################
"""
Conclusion:
The first two examples tell the model performance when where is only one score available for conversion.
This may be used in reality, when we just have one score of a patient but we need to do conversion just based on one score. 
The final developed model with all attributes has a R^2 of 0.729 which is quite reliable.
This idea can be further developed with other tests.
Also, more complicated models can be applied to see if they give better performance.
Once we develop reliable models, we can combine the test results to convert them to another score.
Patients who finish some cognitive tests can avoid doing similar tests.
Furthermore, we may also use the model to double check if a score makes sense.
If a patient completed all the tests and the real value is very different from the predicted value,
it is possible to locate some problem data, such as wrong data by human error.
"""
